{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16d52f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c3b08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74bc026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "import optuna\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import lovasz_losses as L\n",
    "from scipy.ndimage import uniform_filter, gaussian_filter\n",
    "from scipy.ndimage import convolve\n",
    "from skimage.restoration import denoise_bilateral\n",
    "#from util_func.tversky_loss import TverskyLoss  # Make sure this exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83401f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Dataset\n",
    "# -------------------------------\n",
    "class ResizeTensor:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return F.interpolate(tensor.unsqueeze(0), size=self.size, mode='bilinear', align_corners=False).squeeze(0)\n",
    "\n",
    "class SARDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None, image_size=(224, 224), speckle_filter=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.image_size = image_size\n",
    "        self.speckle_filter = speckle_filter.lower() if speckle_filter else None\n",
    "        self.images = sorted(os.listdir(image_dir))\n",
    "        self.masks = sorted(os.listdir(mask_dir))\n",
    "\n",
    "    # def lee_sigma_filter(self, img, size=7, sigma=1.0):\n",
    "    #     mean = uniform_filter(img, size)\n",
    "    #     std = np.sqrt(uniform_filter(img**2, size) - mean**2)\n",
    "    #     mask = np.abs(img - mean) <= sigma * std\n",
    "    #     return np.where(mask, mean, img)\n",
    "    \n",
    "    def lee_sigma_filter(self, img, size=7, sigma=1.0):\n",
    "        mean = uniform_filter(img, size)\n",
    "        std = np.sqrt(uniform_filter(img**2, size) - mean**2)\n",
    "        mask = np.abs(img - mean) <= sigma * std\n",
    "        output = np.where(mask, mean, img)\n",
    "        return output\n",
    "\n",
    "    def refined_lee_filter(self, img, size=7):\n",
    "        # Simplified refined Lee filter version (basic 2-step averaging)\n",
    "        mean = uniform_filter(img, size)\n",
    "        var = uniform_filter((img - mean)**2, size)\n",
    "        cu = np.var(img)\n",
    "        W = var / (var + cu + 1e-6)\n",
    "        filtered = mean + W * (img - mean)\n",
    "        return uniform_filter(filtered, 3)\n",
    "\n",
    "    def apply_speckle_filter(self, img):\n",
    "        return self.lee_sigma_filter(img) if self.speckle_filter == \"lee_sigma\" else img\n",
    "    \n",
    "    def gamma_filter(self, img, size=7):\n",
    "        mean = uniform_filter(img, size)\n",
    "        var = uniform_filter((img - mean) ** 2, size)\n",
    "        b = var / (mean ** 2 + 1e-6)\n",
    "        return mean / (1 + b)\n",
    "\n",
    "    def frost_filter(self, img, size=5, damping_factor=2.0):\n",
    "        padded = np.pad(img, size // 2, mode='reflect')\n",
    "        out = np.zeros_like(img)\n",
    "        for i in range(out.shape[0]):\n",
    "            for j in range(out.shape[1]):\n",
    "                window = padded[i:i+size, j:j+size]\n",
    "                center = window[size // 2, size // 2]\n",
    "                mean = np.mean(window)\n",
    "                var = np.var(window)\n",
    "                coeff_var = var / (mean**2 + 1e-6)\n",
    "                weight = np.exp(-coeff_var * np.abs(window - center) / damping_factor)\n",
    "                weight /= weight.sum()\n",
    "                out[i, j] = np.sum(weight * window)\n",
    "        return out\n",
    "    \n",
    "    def apply_speckle_filter(self, img):\n",
    "        if self.speckle_filter == \"lee\":\n",
    "            return self.lee_filter(img)\n",
    "        elif self.speckle_filter == \"gamma\":\n",
    "            return self.gamma_filter(img)\n",
    "        elif self.speckle_filter == \"frost\":\n",
    "            return self.frost_filter(img)\n",
    "        elif self.speckle_filter == \"refined_lee\":\n",
    "            return self.refined_lee_filter(img)\n",
    "        elif self.speckle_filter == \"lee_sigma\":\n",
    "            return self.lee_sigma_filter(img)\n",
    "        else:\n",
    "            return img  # No filter applied\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.masks[idx])\n",
    "\n",
    "        with rasterio.open(image_path) as src:\n",
    "            image = src.read(1).astype(np.float32)\n",
    "\n",
    "        image = self.apply_speckle_filter(image)\n",
    "        image = (image - image.min()) / (image.max() - image.min() + 1e-6)\n",
    "        image = torch.from_numpy(image).unsqueeze(0)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        mask = Image.open(mask_path)\n",
    "        mask = torch.from_numpy(np.array(mask, dtype=np.int64))\n",
    "\n",
    "        if self.image_size:\n",
    "            mask = F.interpolate(mask.unsqueeze(0).unsqueeze(0).float(), size=self.image_size, mode='nearest').squeeze().long()\n",
    "\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8348d814",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Model\n",
    "# -------------------------------\n",
    "class ViTSegmentation(nn.Module):\n",
    "    def __init__(self, image_size=224, patch_size=16, num_classes=9):\n",
    "        super().__init__()\n",
    "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True, in_chans=1)\n",
    "        self.image_size = image_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.n_patches = (image_size // patch_size) ** 2\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(self.vit.embed_dim, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        feats = self.vit.patch_embed(x)\n",
    "        cls_token = self.vit.cls_token.expand(B, -1, -1)\n",
    "        feats = torch.cat((cls_token, feats), dim=1)\n",
    "        feats = feats + self.vit.pos_embed\n",
    "        feats = self.vit.pos_drop(feats)\n",
    "        feats = self.vit.blocks(feats)\n",
    "        feats = self.vit.norm(feats)\n",
    "\n",
    "        feats = feats[:, 1:, :]\n",
    "        h = w = self.image_size // self.patch_size\n",
    "        feats = feats.permute(0, 2, 1).reshape(B, self.vit.embed_dim, h, w)\n",
    "        feats = F.interpolate(feats, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        return self.decoder(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9854c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluation\n",
    "# -------------------------------\n",
    "\n",
    "import torch\n",
    "\n",
    "# Example class frequencies (you can replace these)\n",
    "class_freq = torch.tensor([\n",
    "    0.0015, 0.0170, 0.2470, 0.2334,\n",
    "    0.0750, 0.1391, 0.1063, 0.0679, 0.1128\n",
    "])\n",
    "\n",
    "# Inverse frequency weights (normalize if desired)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_weights = 1.0 / class_freq\n",
    "class_weights = class_weights / class_weights.sum()  # normalize\n",
    "class_weights = class_weights.to(device)  # ensure it's on GPU\n",
    "\n",
    "\n",
    "def TverskyLoss(logits, targets, alpha=0.7, beta=0.3, gamma=1.0, eps=1e-6):\n",
    "    num_classes = logits.shape[1]\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    targets_one_hot = F.one_hot(targets, num_classes=num_classes).permute(0, 3, 1, 2).float()\n",
    "\n",
    "    TP = (probs * targets_one_hot).sum(dim=(2, 3))\n",
    "    FP = (probs * (1 - targets_one_hot)).sum(dim=(2, 3))\n",
    "    FN = ((1 - probs) * targets_one_hot).sum(dim=(2, 3))\n",
    "\n",
    "    Tversky = (TP + eps) / (TP + alpha * FP + beta * FN + eps)\n",
    "    return (1 - Tversky).pow(gamma).mean()\n",
    "\n",
    "# # combined_loss.py\n",
    "# class CombinedLovaszFocalTverskyLoss(torch.nn.Module):\n",
    "#     def __init__(self, alpha=0.7, beta=0.3, gamma=1.33, lovasz_weight=0.6, tversky_weight=0.4, ce_weight=1):\n",
    "#         super().__init__()\n",
    "#         self.alpha = alpha\n",
    "#         self.beta = beta\n",
    "#         self.gamma = gamma\n",
    "#         self.lovasz_weight = lovasz_weight\n",
    "#         self.tversky_weight = tversky_weight\n",
    "#         self.ce_weight=ce_weight\n",
    "\n",
    "#     def forward(self, logits, targets):\n",
    "#         loss_lovasz = L.lovasz_softmax(F.softmax(logits, dim=1), targets)\n",
    "#         ce_loss_clf = F.cross_entropy(logits, targets)\n",
    "#         loss_tversky = focal_tversky_loss(logits, targets, self.alpha, self.beta, self.gamma)\n",
    "#         return self.lovasz_weight * loss_lovasz + self.tversky_weight * loss_tversky+ self.ce_weight * ce_loss_clf\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, num_classes):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_pixels = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            out = model(x)\n",
    "            preds = torch.argmax(out, dim=1)\n",
    "            total_correct += (preds == y).sum().item()\n",
    "            total_pixels += torch.numel(preds)\n",
    "            all_preds.append(preds.view(-1))\n",
    "            all_targets.append(y.view(-1))\n",
    "\n",
    "    preds_cat = torch.cat(all_preds).cpu().numpy()\n",
    "    targets_cat = torch.cat(all_targets).cpu().numpy()\n",
    "    cm = confusion_matrix(targets_cat, preds_cat, labels=list(range(num_classes)))\n",
    "    ious = np.diag(cm) / (cm.sum(1) + cm.sum(0) - np.diag(cm) + 1e-6)\n",
    "\n",
    "    print(\"Class-wise IoUs:\")\n",
    "    for i, iou in enumerate(ious):\n",
    "        print(f\"Class {i}: IoU = {iou:.4f}\")\n",
    "\n",
    "    return total_correct / total_pixels, ious\n",
    "\n",
    "# -------------------------------\n",
    "# Optuna Objective\n",
    "# -------------------------------\n",
    "def objective(trial):\n",
    "    # Fixed batch size\n",
    "    batch_size = 16\n",
    "\n",
    "    # Hyperparameters to tune\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 3e-3, log=True)\n",
    "    gamma_tversky = trial.suggest_float(\"gamma_tversky\", 1.0, 3.0)\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.1, 0.5)\n",
    "    beta = 1-alpha\n",
    "\n",
    "\n",
    "    ce_w = trial.suggest_float(\"ce_weight\", 0.1, 1.0)\n",
    "    tversky_w = trial.suggest_float(\"tversky_weight\", 0.1, 1.0)\n",
    "    lovasz_w = trial.suggest_float(\"lovasz_weight\", 0.1, 1.0)\n",
    "\n",
    "    # Dataset and loaders\n",
    "    transform = ResizeTensor((224, 224))\n",
    "    dataset = SARDataset(\n",
    "        image_dir=r\"D:\\train_splitted\\sar_images\",\n",
    "        mask_dir=r\"D:\\train_splitted\\labels\",\n",
    "        transform=transform,\n",
    "        image_size=(224, 224),\n",
    "        speckle_filter=\"lee_sigma\"\n",
    "    )\n",
    "    train_size = int(0.95 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ViTSegmentation(image_size=224, num_classes=9).to(device)\n",
    "\n",
    "    # Loss function with weights and gamma_tversky\n",
    "    def total_loss_fn(out, target, class_weights=None):\n",
    "        probs = F.softmax(out, dim=1)\n",
    "        loss_lovasz = L.lovasz_softmax(probs, target)\n",
    "        #loss_tversky = TverskyLoss(out, target, gamma=gamma_tversky)\n",
    "        loss_tversky = TverskyLoss(out, target,alpha=alpha, beta=beta, gamma=gamma_tversky)\n",
    "        if class_weights is not None:\n",
    "            loss_ce = F.cross_entropy(out, target, weight=class_weights)\n",
    "        else:\n",
    "            loss_ce = F.cross_entropy(out, target)\n",
    "        return lovasz_w * loss_lovasz + tversky_w * loss_tversky + ce_w * loss_ce\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "\n",
    "    # Scheduler - ReduceLROnPlateau on validation accuracy\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=0.5, patience=3, verbose=False\n",
    "    )\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(30):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = total_loss_fn(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation step\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_acc, val_ious = evaluate(model, val_loader, num_classes=9)\n",
    "\n",
    "        # Step the scheduler with validation accuracy\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        trial.report(val_acc, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        best_val_acc = max(best_val_acc, val_acc)\n",
    "\n",
    "    return best_val_acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e80f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-18 15:17:25,775] A new study created in memory with name: no-name-02d235f0-432b-4a54-be52-c86e63415e3d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harek\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Main\n",
    "# -------------------------------\n",
    "if __name__ == '__main__':\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=30, timeout=80000)\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value: {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcbe376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d089d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dbfe60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b20be64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496466bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac02af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb25b081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2c045e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f73689f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa51f41d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c316e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b265f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa8f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "import optuna\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import lovasz_losses as L\n",
    "from scipy.ndimage import uniform_filter, gaussian_filter\n",
    "from scipy.ndimage import convolve\n",
    "from skimage.restoration import denoise_bilateral\n",
    "#from util_func.tversky_loss import TverskyLoss  # Make sure this exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697ed541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Dataset\n",
    "# -------------------------------\n",
    "class ResizeTensor:\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        return F.interpolate(tensor.unsqueeze(0), size=self.size, mode='bilinear', align_corners=False).squeeze(0)\n",
    "\n",
    "class SARDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None, image_size=(224, 224), speckle_filter=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.image_size = image_size\n",
    "        self.speckle_filter = speckle_filter.lower() if speckle_filter else None\n",
    "        self.images = sorted(os.listdir(image_dir))\n",
    "        self.masks = sorted(os.listdir(mask_dir))\n",
    "\n",
    "    # def lee_sigma_filter(self, img, size=7, sigma=1.0):\n",
    "    #     mean = uniform_filter(img, size)\n",
    "    #     std = np.sqrt(uniform_filter(img**2, size) - mean**2)\n",
    "    #     mask = np.abs(img - mean) <= sigma * std\n",
    "    #     return np.where(mask, mean, img)\n",
    "    \n",
    "    def lee_sigma_filter(self, img, size=7, sigma=1.0):\n",
    "        mean = uniform_filter(img, size)\n",
    "        std = np.sqrt(uniform_filter(img**2, size) - mean**2)\n",
    "        mask = np.abs(img - mean) <= sigma * std\n",
    "        output = np.where(mask, mean, img)\n",
    "        return output\n",
    "\n",
    "    def refined_lee_filter(self, img, size=7):\n",
    "        # Simplified refined Lee filter version (basic 2-step averaging)\n",
    "        mean = uniform_filter(img, size)\n",
    "        var = uniform_filter((img - mean)**2, size)\n",
    "        cu = np.var(img)\n",
    "        W = var / (var + cu + 1e-6)\n",
    "        filtered = mean + W * (img - mean)\n",
    "        return uniform_filter(filtered, 3)\n",
    "\n",
    "    def apply_speckle_filter(self, img):\n",
    "        return self.lee_sigma_filter(img) if self.speckle_filter == \"lee_sigma\" else img\n",
    "    \n",
    "    def gamma_filter(self, img, size=7):\n",
    "        mean = uniform_filter(img, size)\n",
    "        var = uniform_filter((img - mean) ** 2, size)\n",
    "        b = var / (mean ** 2 + 1e-6)\n",
    "        return mean / (1 + b)\n",
    "\n",
    "    def frost_filter(self, img, size=5, damping_factor=2.0):\n",
    "        padded = np.pad(img, size // 2, mode='reflect')\n",
    "        out = np.zeros_like(img)\n",
    "        for i in range(out.shape[0]):\n",
    "            for j in range(out.shape[1]):\n",
    "                window = padded[i:i+size, j:j+size]\n",
    "                center = window[size // 2, size // 2]\n",
    "                mean = np.mean(window)\n",
    "                var = np.var(window)\n",
    "                coeff_var = var / (mean**2 + 1e-6)\n",
    "                weight = np.exp(-coeff_var * np.abs(window - center) / damping_factor)\n",
    "                weight /= weight.sum()\n",
    "                out[i, j] = np.sum(weight * window)\n",
    "        return out\n",
    "    \n",
    "    def apply_speckle_filter(self, img):\n",
    "        if self.speckle_filter == \"lee\":\n",
    "            return self.lee_filter(img)\n",
    "        elif self.speckle_filter == \"gamma\":\n",
    "            return self.gamma_filter(img)\n",
    "        elif self.speckle_filter == \"frost\":\n",
    "            return self.frost_filter(img)\n",
    "        elif self.speckle_filter == \"refined_lee\":\n",
    "            return self.refined_lee_filter(img)\n",
    "        elif self.speckle_filter == \"lee_sigma\":\n",
    "            return self.lee_sigma_filter(img)\n",
    "        else:\n",
    "            return img  # No filter applied\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.masks[idx])\n",
    "\n",
    "        with rasterio.open(image_path) as src:\n",
    "            image = src.read(1).astype(np.float32)\n",
    "\n",
    "        image = self.apply_speckle_filter(image)\n",
    "        image = (image - image.min()) / (image.max() - image.min() + 1e-6)\n",
    "        image = torch.from_numpy(image).unsqueeze(0)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        mask = Image.open(mask_path)\n",
    "        mask = torch.from_numpy(np.array(mask, dtype=np.int64))\n",
    "\n",
    "        if self.image_size:\n",
    "            mask = F.interpolate(mask.unsqueeze(0).unsqueeze(0).float(), size=self.image_size, mode='nearest').squeeze().long()\n",
    "\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6119ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Model\n",
    "# -------------------------------\n",
    "class ViTSegmentation(nn.Module):\n",
    "    def __init__(self, image_size=224, patch_size=16, num_classes=9):\n",
    "        super().__init__()\n",
    "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True, in_chans=1)\n",
    "        self.image_size = image_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.n_patches = (image_size // patch_size) ** 2\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(self.vit.embed_dim, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        feats = self.vit.patch_embed(x)\n",
    "        cls_token = self.vit.cls_token.expand(B, -1, -1)\n",
    "        feats = torch.cat((cls_token, feats), dim=1)\n",
    "        feats = feats + self.vit.pos_embed\n",
    "        feats = self.vit.pos_drop(feats)\n",
    "        feats = self.vit.blocks(feats)\n",
    "        feats = self.vit.norm(feats)\n",
    "\n",
    "        feats = feats[:, 1:, :]\n",
    "        h = w = self.image_size // self.patch_size\n",
    "        feats = feats.permute(0, 2, 1).reshape(B, self.vit.embed_dim, h, w)\n",
    "        feats = F.interpolate(feats, size=x.shape[2:], mode='bilinear', align_corners=False)\n",
    "        return self.decoder(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5778fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Evaluation\n",
    "# -------------------------------\n",
    "\n",
    "\n",
    "\n",
    "def TverskyLoss(logits, targets, alpha=0.7, beta=0.3, gamma=1.0, eps=1e-6):\n",
    "    num_classes = logits.shape[1]\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    targets_one_hot = F.one_hot(targets, num_classes=num_classes).permute(0, 3, 1, 2).float()\n",
    "\n",
    "    TP = (probs * targets_one_hot).sum(dim=(2, 3))\n",
    "    FP = (probs * (1 - targets_one_hot)).sum(dim=(2, 3))\n",
    "    FN = ((1 - probs) * targets_one_hot).sum(dim=(2, 3))\n",
    "\n",
    "    Tversky = (TP + eps) / (TP + alpha * FP + beta * FN + eps)\n",
    "    return (1 - Tversky).pow(gamma).mean()\n",
    "\n",
    "# # combined_loss.py\n",
    "# class CombinedLovaszFocalTverskyLoss(torch.nn.Module):\n",
    "#     def __init__(self, alpha=0.7, beta=0.3, gamma=1.33, lovasz_weight=0.6, tversky_weight=0.4, ce_weight=1):\n",
    "#         super().__init__()\n",
    "#         self.alpha = alpha\n",
    "#         self.beta = beta\n",
    "#         self.gamma = gamma\n",
    "#         self.lovasz_weight = lovasz_weight\n",
    "#         self.tversky_weight = tversky_weight\n",
    "#         self.ce_weight=ce_weight\n",
    "\n",
    "#     def forward(self, logits, targets):\n",
    "#         loss_lovasz = L.lovasz_softmax(F.softmax(logits, dim=1), targets)\n",
    "#         ce_loss_clf = F.cross_entropy(logits, targets)\n",
    "#         loss_tversky = focal_tversky_loss(logits, targets, self.alpha, self.beta, self.gamma)\n",
    "#         return self.lovasz_weight * loss_lovasz + self.tversky_weight * loss_tversky+ self.ce_weight * ce_loss_clf\n",
    "\n",
    "\n",
    "def evaluate(model, dataloader, num_classes):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_pixels = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            out = model(x)\n",
    "            preds = torch.argmax(out, dim=1)\n",
    "            total_correct += (preds == y).sum().item()\n",
    "            total_pixels += torch.numel(preds)\n",
    "            all_preds.append(preds.view(-1))\n",
    "            all_targets.append(y.view(-1))\n",
    "\n",
    "    preds_cat = torch.cat(all_preds).cpu().numpy()\n",
    "    targets_cat = torch.cat(all_targets).cpu().numpy()\n",
    "    cm = confusion_matrix(targets_cat, preds_cat, labels=list(range(num_classes)))\n",
    "    ious = np.diag(cm) / (cm.sum(1) + cm.sum(0) - np.diag(cm) + 1e-6)\n",
    "\n",
    "    print(\"Class-wise IoUs:\")\n",
    "    for i, iou in enumerate(ious):\n",
    "        print(f\"Class {i}: IoU = {iou:.4f}\")\n",
    "\n",
    "    return total_correct / total_pixels, ious\n",
    "\n",
    "# -------------------------------\n",
    "# Optuna Objective\n",
    "# -------------------------------\n",
    "def objective(trial):\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [4, 8, 16])\n",
    "    gamma_scheduler = trial.suggest_float(\"gamma_scheduler\", 0.1, 0.9)\n",
    "    gamma_tversky = trial.suggest_float(\"gamma_tversky\", 1.0, 3.0)\n",
    "    \n",
    "\n",
    "    #gamma = trial.suggest_float(\"gamma\", 0.1, 0.9)\n",
    "    ce_w = trial.suggest_float(\"ce_weight\", 0.1, 1.0)\n",
    "    tversky_w = trial.suggest_float(\"tversky_weight\", 0.1, 1.0)\n",
    "    lovasz_w = trial.suggest_float(\"lovasz_weight\", 0.1, 1.0)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\", \"AdamW\"])\n",
    "    # image_dir=\"C:/Users/SSINGH21/Documents/IEEE/train/sar_images\",\n",
    "    #     mask_dir=\"C:/Users/SSINGH21/Documents/IEEE/train/labels/\" \n",
    "    transform = ResizeTensor((224, 224))\n",
    "    dataset = SARDataset(\n",
    "        image_dir=r\"D:\\train_splitted\\sar_images\",\n",
    "        mask_dir=r\"D:\\train_splitted\\labels\",\n",
    "        transform=transform,\n",
    "        image_size=(224, 224),\n",
    "        speckle_filter=\"lee_sigma\"\n",
    "    )\n",
    "\n",
    "    train_size = int(0.95 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ViTSegmentation(image_size=224, num_classes=9).to(device)\n",
    "\n",
    "    \n",
    "\n",
    "    def total_loss_fn(out, target):\n",
    "       probs = F.softmax(out, dim=1)  # Apply softmax before passing to lovasz\n",
    "       loss_lovasz = L.lovasz_softmax(probs, target)\n",
    "       loss_tversky = TverskyLoss(out, target,gamma=gamma_tversky)\n",
    "       loss_ce = F.cross_entropy(out, target)\n",
    "       return lovasz_w * loss_lovasz + tversky_w * loss_tversky + ce_w * loss_ce\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=gamma_scheduler)\n",
    "\n",
    "    best_val_acc = 0\n",
    "    for epoch in range(30):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = total_loss_fn(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        val_acc, val_ious = evaluate(model, val_loader, num_classes=9)\n",
    "        trial.report(val_acc, epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "        best_val_acc = max(best_val_acc, val_acc)\n",
    "\n",
    "    return best_val_acc\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
